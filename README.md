# ğŸ¤– RAG Bot - Intelligent Document Q&A System

A powerful Retrieval-Augmented Generation (RAG) chatbot that can answer questions about your documents using state-of-the-art AI models. Built with FastAPI, React, and Hugging Face Transformers.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-yellow)](https://huggingface.co/)

## âœ¨ Features

- ğŸ“š **Document Processing**: Supports TXT, PDF, and DOCX files
- ğŸ” **Smart Search**: FAISS-powered vector similarity search
- ğŸ§  **Intelligent Responses**: Uses Hugging Face models for text generation
- ğŸŒ **Modern Web UI**: React-based interface with real-time chat
- ğŸ”„ **MCP Protocol**: Model Context Protocol support for advanced integrations
- ğŸ¯ **Hybrid Mode**: Handles both document-specific and general knowledge questions
- ğŸ“Š **System Statistics**: Monitor document count and system status
- ğŸ”’ **Secure Configuration**: Environment-based API key management

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 16+ (for React UI)
- Hugging Face API Token ([Get one here](https://huggingface.co/settings/tokens))

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/yourusername/rag-bot.git
   cd rag-bot
   ```

2. **Set up Python environment**

   ```bash
   python -m venv virtualenv

   # On Windows:
   virtualenv\\Scripts\\activate

   # On Linux/Mac:
   source virtualenv/bin/activate

   pip install -r requirements.txt
   ```

3. **Configure environment variables**

   ```bash
   cp .env.example .env
   ```

   Edit `.env` and add your Hugging Face token:

   ```env
   HF_TOKEN=your-hugging-face-token-here
   SERVER_HOST=0.0.0.0
   SERVER_PORT=8000
   DEBUG=True
   ```

4. **Run the application**

   **Option A: React Web UI (Recommended)**

   ```bash
   # Terminal 1: Start backend
   python web_server.py

   # Terminal 2: Start React UI
   cd web_ui
   npm install
   npm start
   ```

   Access at: http://localhost:3000

   **Option B: Simple Web Interface**

   ```bash
   python simple_web_app.py
   ```

   Access at: http://localhost:8000

## ğŸ“– Usage

### Adding Documents

1. Use the web interface to upload TXT, PDF, or DOCX files
2. Documents are automatically processed and indexed
3. Start asking questions about your content!

### Example Questions

**Document-based questions:**

- "What is machine learning?"
- "Explain the types of neural networks"
- "How does the training process work?"

**General knowledge questions:**

- "What is Python programming?"
- "Tell me about artificial intelligence"
- "How do computers work?"

### REST API Usage

The system provides a REST API for programmatic access:

```python
import requests

# Ask a question
response = requests.post("http://localhost:8000/ask",
    json={"question": "What is machine learning?"})
print(response.json()["answer"])

# Upload a document
with open("document.pdf", "rb") as f:
    response = requests.post("http://localhost:8000/upload",
        files={"file": f})

# Search documents
response = requests.post("http://localhost:8000/search",
    json={"query": "neural networks", "top_k": 5})
print(response.json()["results"])
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React UI      â”‚    â”‚   FastAPI       â”‚    â”‚  RAG Pipeline   â”‚
â”‚   (Frontend)    â”‚â—„â”€â”€â–ºâ”‚   (Backend)     â”‚â—„â”€â”€â–ºâ”‚  (AI Engine)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Document      â”‚    â”‚   Vector Store  â”‚
                       â”‚   Processor     â”‚    â”‚   (FAISS)       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

- **Document Processor**: Handles PDF, DOCX, and TXT files with intelligent chunking
- **Vector Store**: FAISS-based similarity search with persistence
- **RAG Pipeline**: Combines retrieval with Hugging Face generation models
- **Web Interface**: Modern React UI with real-time chat capabilities
- **MCP Server**: Model Context Protocol implementation for tool integration

## ğŸ”§ Configuration

Key configuration options in `.env`:

```bash
# Required: Get from https://huggingface.co/settings/tokens
HF_TOKEN=your-hugging-face-token

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# Development Settings
DEBUG=True
LOG_LEVEL=INFO
```

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
python test_rag_system.py
```

Test specific components:

```bash
# Test document processing
python -c "from mcp_servers.rag_server.document_processor import DocumentProcessor; print('âœ… Document processor working')"

# Test vector store
python -c "from mcp_servers.rag_server.vector_store import VectorStore; print('âœ… Vector store working')"
```

## ğŸ“ Project Structure

```
rag-bot/
â”œâ”€â”€ ğŸ“„ README.md                 # Project documentation
â”œâ”€â”€ ğŸ”§ config.py                 # Configuration management
â”œâ”€â”€ ğŸ“¦ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸŒ web_server.py             # FastAPI backend
â”œâ”€â”€ ğŸ•¸ï¸ simple_web_app.py        # Self-contained web interface
â”œâ”€â”€ ğŸ” test_rag_system.py        # Comprehensive test suite
â”œâ”€â”€ ğŸ“š data/                     # Sample documents
â”‚   â”œâ”€â”€ ai_basics.txt
â”‚   â”œâ”€â”€ machine_learning.txt
â”‚   â””â”€â”€ rag_explanation.txt
â”œâ”€â”€ ğŸ–¥ï¸ web_ui/                   # React frontend
â”‚   â”œâ”€â”€ ğŸ“¦ package.json
â”‚   â”œâ”€â”€ ğŸ¨ src/components/       # React components
â”‚   â”‚   â”œâ”€â”€ ChatInterface.js
â”‚   â”‚   â”œâ”€â”€ SearchInterface.js
â”‚   â”‚   â”œâ”€â”€ DocumentUpload.js
â”‚   â”‚   â””â”€â”€ SystemStats.js
â”‚   â””â”€â”€ ğŸ¯ public/
â”œâ”€â”€ ğŸ”Œ mcp_servers/              # MCP Protocol implementation
â”‚   â”œâ”€â”€ ğŸ“¡ main.py
â”‚   â””â”€â”€ ğŸ¤– rag_server/
â”‚       â”œâ”€â”€ ğŸ“„ document_processor.py
â”‚       â”œâ”€â”€ ğŸ—ƒï¸ vector_store.py
â”‚       â”œâ”€â”€ ğŸ§  rag_pipeline.py
â”‚       â””â”€â”€ ğŸ–¥ï¸ server.py
â”œâ”€â”€ ğŸ” .env.example             # Environment template
â””â”€â”€ ğŸ” .env                     # Your environment variables (not in git)
```

## ğŸŒŸ Advanced Features

### MCP Protocol Support

Run as an MCP server for integration with other tools:

```bash
python mcp_servers/rag_server/server.py
```

### Custom Models

Modify `config.py` to use different Hugging Face models:

```python
# In config.py
DEFAULT_GENERATION_MODEL = "microsoft/DialoGPT-medium"
DEFAULT_EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
```

### Batch Document Processing

Process multiple documents programmatically:

```python
from mcp_servers.rag_server.document_processor import DocumentProcessor
from mcp_servers.rag_server.vector_store import VectorStore

processor = DocumentProcessor()
vector_store = VectorStore()

# Process all documents in a directory
import os
for filename in os.listdir("documents/"):
    if filename.endswith(('.txt', '.pdf', '.docx')):
        docs = processor.process_file(f"documents/{filename}")
        vector_store.add_documents(docs)
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes and test thoroughly
4. Commit your changes: `git commit -am 'Add feature'`
5. Push to the branch: `git push origin feature-name`
6. Submit a pull request

### Development Setup

```bash
# Install development dependencies
pip install -r requirements.txt
pip install black flake8 pytest

# Run code formatting
black .

# Run linting
flake8 .

# Run tests
pytest
```

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”— Links

- [Hugging Face Models](https://huggingface.co/models)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://reactjs.org/)
- [FAISS Documentation](https://faiss.ai/)
- [Model Context Protocol](https://modelcontextprotocol.io/)

## ğŸ†˜ Troubleshooting

### Common Issues

**1. "HF_TOKEN is required" Error**

- Make sure you've created `.env` file from `.env.example`
- Add your valid Hugging Face token
- Verify token is active at https://huggingface.co/settings/tokens

**2. "Port already in use" Error**

- Check if another process is using port 8000 or 3000
- Kill the process or change the port in configuration

**3. React UI not connecting to backend**

- Ensure both frontend (port 3000) and backend (port 8000) are running
- Check CORS settings in `web_server.py`

**4. Document upload fails**

- Verify the file format is supported (TXT, PDF, DOCX)
- Check file size limits
- Ensure proper permissions on upload directory

### Getting Help

If you encounter any issues:

1. Check the [Issues](https://github.com/yourusername/rag-bot/issues) page
2. Review the configuration in `.env`
3. Ensure all dependencies are installed correctly
4. Verify your Hugging Face token is valid
5. Check the logs for error messages

## ğŸ™ Acknowledgments

- [Hugging Face](https://huggingface.co/) for providing excellent models and APIs
- [Facebook AI Research](https://ai.facebook.com/) for FAISS vector search
- [FastAPI](https://fastapi.tiangolo.com/) team for the amazing web framework
- [React](https://reactjs.org/) team for the frontend framework
- [LangChain](https://langchain.com/) for RAG framework inspiration
- The open-source community for all the amazing tools and libraries

---

## â­ Star this repo if you found it helpful!

Made with â¤ï¸ for the AI community
